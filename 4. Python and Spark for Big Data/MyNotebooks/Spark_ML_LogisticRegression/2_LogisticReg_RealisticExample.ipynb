{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "marine-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "isolated-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('logreg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dedicated-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "df = spark.read.csv('titanic.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pregnant-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "junior-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict survivability (YES/NO) based on features\n",
    "# Binary Classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "headed-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "myColumns = df.select(['Survived','Pclass','Sex','Age','SibSp',\n",
    "                      'Parch','Fare','Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cosmetic-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme way of dealing with data!\n",
    "myFinalData = myColumns.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "peaceful-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us handle categorical columns!\n",
    "from pyspark.ml.feature import (VectorAssembler, VectorIndexer,\n",
    "                                OneHotEncoder, StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "equivalent-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index string columns\n",
    "genderIndexer = StringIndexer(inputCol='Sex',\n",
    "                              outputCol='SexIndex')\n",
    "embarkIndexer = StringIndexer(inputCol='Embarked',\n",
    "                              outputCol='EmbarkIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "modern-variation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encode the Indexes to their actual Categories\n",
    "# Column Data              -> A       B       C\n",
    "# Through Indexing         -> 0       1       2\n",
    "# Through One-Hot Encoding -> [1,0,0] [1,0,1] [1,1,0]\n",
    "\n",
    "genderEncoder = OneHotEncoder(inputCol='SexIndex',\n",
    "                              outputCol='SexVec')\n",
    "embarkEncoder = OneHotEncoder(inputCol='EmbarkIndex',\n",
    "                              outputCol='EmbarkVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "permanent-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Vector Assembler to transform your data for ML\n",
    "assembler = VectorAssembler(inputCols=['Pclass','SexVec',\n",
    "                                       'Age','SibSp',\n",
    "                                       'Parch','Fare',\n",
    "                                       'EmbarkVec'],\n",
    "                            outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "under-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for your Machine Learning Model\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "decimal-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the model\n",
    "logReg = LogisticRegression(featuresCol='features',\n",
    "                            labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "reserved-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE CREATION\n",
    "pipeline = Pipeline(stages=[genderIndexer,embarkIndexer,\n",
    "                            genderEncoder,embarkEncoder,\n",
    "                            assembler,logReg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "environmental-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_data,test_data = myFinalData.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "starting-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the Model to train_data\n",
    "fitModel = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "million-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on test_data\n",
    "results = fitModel.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "helpful-furniture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(['Survived','prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "greatest-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE YOUR MODEL\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "plain-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'prediction' is the default name of the column\n",
    "eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                     labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bright-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area Under the Curve\n",
    "AUC = eval.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "better-shelter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7642325025292008"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC # 76.4% Area Under Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-necklace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
